#Importing the libraries 
from selenium import webdriver 
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup
import requests
import time
import os

APP_ROOT = os.path.dirname(os.path.abspath(__file__))

#chrome arguments 
option = webdriver.ChromeOptions()
option.add_argument(" â€” incognito")
option.add_argument('--ignore-certificate-errors')
option.add_argument('--ignore-ssl-errors')


counter = 0

def extracting_links(i):
    """To extract the links from the webpage"""
    
    global links
    page = browser.find_element_by_link_text(i)
    browser.implicitly_wait(5)
    page.click()
    browser.implicitly_wait(5)

    pin_element_1 = browser.find_elements_by_xpath('//div[@id="c_articlelist_stories_1"]//ul[@id="content"]//li//a[@*]')
    pin_element_2 = browser.find_elements_by_xpath('//div[@id="c_articlelist_stories_2"]/ul[1]//li//a[@*]')
    links_1 = [x.get_attribute("href") for x in pin_element_1]
    links_2 = [x.get_attribute("href") for x in pin_element_2]

    links_total = links_1 + links_2 
    
    for i in links_total:
        if i not in links:
            links.append(i)
    print(links)
    print(len(links))
    print(browser.current_url)
    return links


def extract_content(links):
    """To extract the article from the page"""

    for url in links:

        global counter
        counter+=1
        response = requests.get(url,timeout=5)
        content = BeautifulSoup(response.content, "html5lib")
        article = ''

        article_html = content.find('div', attrs={"class": "_3WlLe clearfix"})
        #article_html = article.encode("utf-8")
        for i in article_html:
            try:
                x = i.text
                article = article + '\n' + x
            except AttributeError:
                y = str(i)
                article = article + '\n' + y
				
        print('article no:',counter)
        print('\n',str(article.encode("utf-8")))

        save_article(str(article.encode("utf-8")),counter)

def save_article(article,counter):
    """To save the articles in the specified path"""

    filepath = os.path.join(saved_path,'article_' + str(counter) + '.txt')
    if not os.path.exists(saved_path):
        os.makedirs(saved_path)
    f = open(filepath,'w')
    f.write(article)


# To set up the browser, obtain the URL,Number of pages to extract from and, path to save the articles in:
browser = webdriver.Chrome(executable_path=os.path.join(APP_ROOT ,"chromedriver.exe"), chrome_options=option)
premise = input("Enter URL of Times of India article: ")
saved_path = os.path.join(APP_ROOT,"txt_files")
pages = 1
#  C:/Users/admin/Desktop/temp_p
# https://timesofindia.indiatimes.com/business/india-business/sensex
browser.get(premise)

links = []
pages = pages + 1
for i in range(1,pages):
    i = str(i)
    extracting_links(i)
extract_content(links)

    